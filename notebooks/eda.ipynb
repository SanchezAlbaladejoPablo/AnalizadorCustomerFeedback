{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1: Análisis Exploratorio de Datos (EDA) - Customer Feedback Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook, realizaremos un análisis exploratorio básico sobre el dataset de Amazon Fine Food Reviews. Nuestro objetivo es entender la estructura de los datos, la distribución de las puntuaciones (nuestra variable objetivo) y obtener algunas visualizaciones iniciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos y Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', 150)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la ruta al dataset procesado\n",
    "# Si el script de preprocesamiento aún no se ha ejecutado, usaremos el dataset crudo.\n",
    "processed_data_path = \"../data/processed/processed_reviews.csv\"\n",
    "raw_data_path = \"../data/raw/Reviews.csv\"\n",
    "\n",
    "if os.path.exists(processed_data_path):\n",
    "    print(f\"Cargando dataset procesado desde {processed_data_path}\")\n",
    "    df = pd.read_csv(processed_data_path)\n",
    "else:\n",
    "    print(f\"Dataset procesado no encontrado. Cargando dataset crudo desde {raw_data_path}\")\n",
    "    df = pd.read_csv(raw_data_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estadísticas Descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "print(\"\nInformación del DataFrame:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:** El script de preprocesamiento ya maneja los valores nulos y duplicados. Si estamos viendo el dataset crudo, es normal encontrar algunos nulos, especialmente en `ProfileName`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribución de la Variable Objetivo (Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Score', data=df, palette='viridis')\n",
    "plt.title('Distribución de Puntuaciones (Score)', fontsize=16)\n",
    "plt.xlabel('Puntuación', fontsize=12)\n",
    "plt.ylabel('Número de Reseñas', fontsize=12)\n",
    "plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:** La gran mayoría de las reseñas tienen una puntuación de 5. Esto indica un fuerte desbalance de clases. Las puntuaciones de 1, 2 y 3 son mucho menos frecuentes. Para nuestro modelo de clasificación de sentimiento, podríamos agrupar las puntuaciones:\n",
    "- **Positivo:** 4, 5\n",
    "- **Negativo:** 1, 2\n",
    "- **Neutral:** 3 (a menudo se descarta para simplificar a una clasificación binaria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la Clase de Sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(score):\n",
    "    if score <= 2:\n",
    "        return 'Negativo'\n",
    "    elif score == 3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positivo'\n",
    "\n",
    "df['Sentiment'] = df['Score'].apply(map_sentiment)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='Sentiment', data=df, order=['Positivo', 'Neutral', 'Negativo'], palette='magma')\n",
    "plt.title('Distribución de Sentimiento', fontsize=16)\n",
    "plt.xlabel('Sentimiento', fontsize=12)\n",
    "plt.ylabel('Número de Reseñas', fontsize=12)\n",
    "plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Longitud de las Reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el texto procesado si está disponible\n",
    "text_col = 'processed_text' if 'processed_text' in df.columns else 'Text'\n",
    "\n",
    "df['text_length'] = df[text_col].str.len()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['text_length'], bins=50, kde=True)\n",
    "plt.title('Distribución de la Longitud de las Reseñas', fontsize=16)\n",
    "plt.xlabel('Longitud del Texto', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "plt.xlim(0, 1500) # Limitar el eje x para mejor visualización\n",
    "plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:** La mayoría de las reseñas son relativamente cortas, con una distribución que tiene una cola larga hacia la derecha. Esto es típico en datos de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones del EDA" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Desbalance de Clases:** El dataset está fuertemente desbalanceado hacia reseñas positivas (Score 5). Esto es crucial y debemos tenerlo en cuenta al entrenar y evaluar nuestros modelos. Técnicas como el sobremuestreo (oversampling) de clases minoritarias, el submuestreo (undersampling) de la clase mayoritaria o el uso de pesos de clase (`class_weight`) en los modelos pueden ser necesarias.\n",
    "2. **Definición del Problema:** Para la clasificación de sentimiento, una aproximación binaria (Positivo vs. Negativo), ignorando las reseñas neutrales (Score 3), suele ser un buen punto de partida para simplificar el problema y obtener un baseline más claro.\n",
    "3. **Limpieza de Datos:** El preprocesamiento es fundamental. El script `preprocessing.py` ya se encarga de la limpieza, pero este EDA confirma la necesidad de manejar nulos, duplicados y de normalizar el texto.\n",
    "4. **Feature Engineering:** La longitud del texto podría ser una feature simple pero útil. Podríamos explorar si la longitud de la reseña se correlaciona con el sentimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

